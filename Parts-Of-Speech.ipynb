{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTS OF SPEECH TAGS::\n",
    "\n",
    "-> CC - Coordinating Conjunction: Connects words or groups of words. Examples: 'and', 'but', 'or'.\n",
    "\n",
    "-> CD - Cardinal Number: Represents numerical values. Examples: 'one', 'two', 'three'.\n",
    "\n",
    "-> DT - Determiner: Introduces a noun. Examples: 'the', 'this', 'those'.\n",
    "\n",
    "-> JJ - Adjective: Modifies or describes nouns or pronouns. Examples: 'big', 'beautiful'.\n",
    "\n",
    "-> NN - Noun: Represents people, places, things, or ideas. Examples: 'dog', 'city', 'love'.\n",
    "\n",
    "-> PRP - Personal Pronoun: Stands for specific persons or things. Examples: 'I', 'you', 'he', 'she'.\n",
    "\n",
    "-> VB - Verb Base Form: Infinitive forms of verbs. Examples: 'eat', 'write', 'play'.\n",
    "\n",
    "== RB - Adverb: Modifies verbs, adjectives, or other adverbs. Examples: 'quickly', 'very', 'often'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custome_StopWords \n",
    "custom_stopwords = [\n",
    "     'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \n",
    "    \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', \n",
    "    'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", \n",
    "    'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', \n",
    "    'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', \n",
    "    'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', \n",
    "    'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', \n",
    "    'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', \n",
    "    'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', \n",
    "    'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', \n",
    "    'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', \n",
    "    'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', \n",
    "    'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', \n",
    "    'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \n",
    "    \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \n",
    "    \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \n",
    "    \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I iDream India strong, self-reliant, self-assured. India proud equal partner world order characterized peace justice. I dream India prosperous, healthy, secure, compassionate. India bridges economic disparities social inequalities.\" Dr. Kalam's speeches often emphasized role youth nation-building, technological advancement, importance innovation education prosperous future. Please note brief excerpt, Dr. Kalam delivered numerous speeches throughout lifetime, containing valuable insights messages. speeches widely available, explore impactful words searching specific titles themes speeches. People\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' I iDream of an India that is strong, self-reliant, and self-assured.',\n",
       " 'An India that is a proud and equal partner in a world order that is characterized by peace and justice.',\n",
       " 'I dream of an India that is prosperous, healthy, secure, and compassionate.',\n",
       " 'An India that bridges economic disparities and social inequalities.\"',\n",
       " \"Dr. Kalam's speeches often emphasized the role of youth in nation-building, technological advancement, and the importance of innovation and education for a prosperous future.\",\n",
       " 'Please note that this is just a brief excerpt, and Dr. Kalam has delivered numerous speeches throughout his lifetime, each containing valuable insights and messages.',\n",
       " 'His speeches are widely available, and you can explore more of his impactful words by searching for specific titles or themes of his speeches.',\n",
       " 'People']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"\"\" I iDream of an India that is strong, self-reliant, and self-assured. An India that is a proud and equal partner in a world order that is characterized by peace and justice. I dream of an India that is prosperous, healthy, secure, and compassionate. An India that bridges economic disparities and social inequalities.\"\n",
    "\n",
    "Dr. Kalam's speeches often emphasized the role of youth in nation-building, technological advancement, and the importance of innovation and education for a prosperous future.\n",
    "\n",
    "Please note that this is just a brief excerpt, and Dr. Kalam has delivered numerous speeches throughout his lifetime, each containing valuable insights and messages. His speeches are widely available, and you can explore more of his impactful words by searching for specific titles or themes of his speeches.\n",
    "People \"\"\"\n",
    "\n",
    "words = corpus.split()\n",
    "# Filter out stopwords using the custom list\n",
    "filtered_corpus = ' '.join([word for word in words if word.lower() not in custom_stopwords])\n",
    "print(filtered_corpus)\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#Performing tokenizer List will get by using sent_tokenize\n",
    "sentences = nltk.sent_tokenize(corpus)\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-What Actually Happening in below code : \n",
    "-> iterating trhough eachsentence\n",
    "-> converting to words\n",
    "-> after converting applying stopwords\n",
    "->remove stopwords and whatevere words are present and do find parts of speech \n",
    "-> using pos_tag()\n",
    "\n",
    "INDETAIL: \n",
    "-> Iteration through Sentences: The code iterates through each sentence.\n",
    "\n",
    "-> Converting to Words: It tokenizes each sentence into words using NLTK's \n",
    "-> word_tokenize() function.\n",
    "\n",
    "-> Applying Stopwords: It applies a filtering mechanism to remove words that are present in a custom set of stopwords (custom_stopwords), which helps eliminate common words that might not contribute much to the meaning of the text.\n",
    "\n",
    "-> Stemming: The code is expected to perform stemming on the words (represented by the variable stemmer). However, the stemming functionality is not utilized in the provided code snippet.\n",
    "\n",
    "-> Part-of-Speech (POS) Tagging: After removing the stopwords, it utilizes NLTK's pos_tag() function to perform Part-of-Speech tagging on the remaining words in each sentence.\n",
    "\n",
    "-> Printing POS Tags: The code then prints the Part-of-Speech tags for each word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('average_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 'JJ'), ('idream', 'VBP'), ('india', 'NN'), ('strong', 'JJ'), (',', ','), ('self-reli', 'JJ'), (',', ','), ('self-assur', 'JJ'), ('.', '.')]\n",
      "[('india', 'JJ'), ('proud', 'JJ'), ('equal', 'JJ'), ('partner', 'NN'), ('world', 'NN'), ('order', 'NN'), ('character', 'NN'), ('peac', 'NN'), ('justic', 'NN'), ('.', '.')]\n",
      "[('i', 'JJ'), ('dream', 'NN'), ('india', 'NN'), ('prosper', 'NN'), (',', ','), ('healthi', 'NN'), (',', ','), ('secur', 'NN'), (',', ','), ('compassion', 'NN'), ('.', '.')]\n",
      "[('india', 'NN'), ('bridg', 'NN'), ('econom', 'NN'), ('dispar', 'VBP'), ('social', 'JJ'), ('inequ', 'NN'), ('.', '.'), ('``', '``')]\n",
      "[('dr.', 'NN'), ('kalam', 'NN'), (\"'s\", 'POS'), ('speech', 'NN'), ('often', 'RB'), ('emphas', 'JJ'), ('role', 'NN'), ('youth', 'NN'), ('nation-build', 'JJ'), (',', ','), ('technolog', 'JJ'), ('advanc', 'NN'), (',', ','), ('import', 'NN'), ('innov', 'NN'), ('educ', 'FW'), ('prosper', 'NN'), ('futur', 'NN'), ('.', '.')]\n",
      "[('pleas', 'JJ'), ('note', 'NN'), ('brief', 'NN'), ('excerpt', 'NN'), (',', ','), ('dr.', 'JJ'), ('kalam', 'NN'), ('deliv', 'NN'), ('numer', 'NN'), ('speech', 'NN'), ('throughout', 'IN'), ('lifetim', 'NN'), (',', ','), ('contain', 'VBP'), ('valuabl', 'JJ'), ('insight', 'JJ'), ('messag', 'NN'), ('.', '.')]\n",
      "[('speech', 'NN'), ('wide', 'JJ'), ('avail', 'NN'), (',', ','), ('explor', 'JJ'), ('impact', 'NN'), ('word', 'NN'), ('search', 'NN'), ('specif', 'NN'), ('titl', 'JJ'), ('theme', 'NN'), ('speech', 'NN'), ('.', '.')]\n",
      "[('peopl', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# we WIll find out of Pos tag\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])\n",
    "    # Applying custom stop words and stemming\n",
    "    words = [word for word in words if word.lower() not in custom_stopwords]\n",
    "    # sentences[i] = ' '.join(words)  # Converting words back to sentences\n",
    "    \n",
    "    pos_tag = nltk.pos_tag(words)\n",
    "    print(pos_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR SINGLE SENTENCE A SAMPLE CODE IS BEIGN GIVE BELOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taj: NNP\n",
      "Mahal: NNP\n",
      "is: VBZ\n",
      "a: DT\n",
      "Beautiful: JJ\n",
      "Monument: NN\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "corpusneww = \"Taj Mahal is a Beautiful Monument\"\n",
    "words = nltk.word_tokenize(corpusneww)\n",
    "pos_tag = nltk.pos_tag(words)\n",
    "\n",
    "# Display POS tags vertically\n",
    "for word, tag in pos_tag:\n",
    "    print(f'{word}: {tag}')\n",
    "\n",
    "#NNP (Proper Noun, Singular): \n",
    "#VBZ (Verb, 3rd person singular present):\n",
    "#JJ (Adjective): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
